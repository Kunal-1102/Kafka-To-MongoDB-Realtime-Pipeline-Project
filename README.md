# Kafka-To-MongoDB-Realtime-Pipeline-Project
Data Engineering Pipeline using Confluent Kafka and MongoDB

## Introduction
This data engineering project integrates Confluent Kafka and MongoDB to create a robust real-time data pipeline. Kafka streamlines the ingestion and processing of high-volume data events, while MongoDB offers scalable, flexible storage and querying.Together, they enable efficient data flow and management, facilitating real-time analytics and dynamic data handling.

## Architecture Diagram
![Architecture Diagram](https://github.com/Kunal-1102/Kafka-To-MongoDB-Realtime-Pipeline-Project/blob/main/Kafka-Mongo-Architecture-Diagram.jpg)

## Technology Used
1. Confluent Kafka
2. Visual Studio Code
3. MongoDB Atlas

## Dataset 
The link for the data is - https://github.com/Kunal-1102/Kafka-To-MongoDB-Realtime-Pipeline-Project/blob/main/retail_data.csv

## Scripts Used
1. [Kafka-Producer-Code](https://github.com/Kunal-1102/Kafka-To-MongoDB-Realtime-Pipeline-Project/blob/main/kafka_producer_code.py)
2. [Schema-Avro-Format](https://github.com/Kunal-1102/Kafka-To-MongoDB-Realtime-Pipeline-Project/blob/main/reatil_data_avro_schema.json)
